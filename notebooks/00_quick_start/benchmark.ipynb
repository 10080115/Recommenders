{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Benchmarking Collaborative Filtering Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmarking applies to collaborative filtering algorithms available in Microsoft/Recommenders repository like Spark ALS, Surprise SVD, Microsoft SAR, etc.\n",
    "\n",
    "## Experimentation setup:\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in recommending list of items.\n",
    "* Datasets\n",
    "  * Movielens 100K.\n",
    "  * Movielens 1M.\n",
    "  * Movielens 10M.\n",
    "  * Movielens 20M.\n",
    "* Data split\n",
    "  * The data is split into train, valid, and test sets.\n",
    "  * The split ratios are 60-20-20 for train, valid, and test datasets, respectively.\n",
    "  * The splitting is performed in a chronological and stratified way, which means that, ratings of each user will be split by timestamps with regard to the split ratios, and the same set of users appear in the train, valid, and test datasets.\n",
    "  * Only users with more than 10 ratings are kept, to make sure the split is valid.\n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * It is well known in the literature that cross-validation is tricky for model validation. Only hyperparameter sweeping is performed to select the optimal model on a grid of hyper parameters. Knowing that, depending on actual business scenario, evaluation metric of interest may vary, recall is used in our benchmarking to select the optimal model. \n",
    "  * Hyper parameter range is chosen empirically. This may affect the final evaluation results. \n",
    "* Evaluation metrics\n",
    "  * Precision@k.\n",
    "  * Recall@k.\n",
    "  * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "  * Mean-average-precision (MAP). \n",
    "  * In the evaluation metrics above, k = 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.0 | packaged by conda-forge | (default, Feb  9 2017, 14:36:55) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Spark version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import papermill as pm\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType\n",
    "\n",
    "from reco_utils.dataset.url_utils import maybe_download\n",
    "from reco_utils.dataset.movielens import load_spark_df\n",
    "from reco_utils.dataset.spark_splitters import spark_chrono_split\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRankingEvaluation\n",
    "from reco_utils.evaluation.parameter_sweep import generate_param_grid\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ALS pySpark\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\")\\\n",
    "    .config(\"spark.executor.cores\", \"32\")\\\n",
    "    .config(\"spark.executor.memory\", \"8g\")\\\n",
    "    .config(\"spark.memory.fraction\", \"0.9\")\\\n",
    "    .config(\"spark.memory.stageFraction\", \"0.3\")\\\n",
    "    .config(\"spark.executor.instances\", 1)\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"36000s\")\\\n",
    "    .config(\"spark.network.timeout\", \"10000000s\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"50g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# Metric for selection\n",
    "SELECTION_METRIC = \"recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def _find_key_value(d, key):\n",
    "    '''\n",
    "    A private method to find value to a key in a nested dictionary. This is used to get values of metrics.\n",
    "    It can also be exported as a general utility function if necessary.\n",
    "    '''\n",
    "    if key in d: return d[key]\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            value = self._find_key_value(v, key)\n",
    "            if value is not None:\n",
    "                return value\n",
    "\n",
    "def _is_better(a, b, metric):\n",
    "    '''\n",
    "    Check if a is better than b measured by metric. \n",
    "\n",
    "    return: True if a is \"better\" than b.\n",
    "    '''\n",
    "    if metric in [\"rmse\", \"rsquared\"]:\n",
    "        return a < b\n",
    "    elif metric in [\"map\", \"ndcg\", \"recall\", \"precision\", \"diversity\"]:\n",
    "        return a > b\n",
    "    else:\n",
    "        raise ValueError(\"Metric {} not recognised.\".format(metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data schema\n",
    "headers = {\n",
    "    \"col_user\": \"UserId\",\n",
    "    \"col_item\": \"MovieId\",\n",
    "    \"col_timestamp\": \"Timestamp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "dfs = load_spark_df(spark=spark, size=MOVIELENS_DATA_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data w.r.t the experimentation protocol.\n",
    "dfs_train, dfs_valid, dfs_test = spark_chrono_split(\n",
    "    dfs,\n",
    "    filter_by=\"user\", \n",
    "    min_rating=10,\n",
    "    ratio=[0.6, 0.2, 0.2],\n",
    "    **headers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_algorithms = [\"als\", \"sar\", \"svd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_params = {\n",
    "    \"als\": {\n",
    "        \"rank\": [10, 15],\n",
    "        \"regParam\": 0.01,\n",
    "        \"alpha\": 0.1\n",
    "    },\n",
    "    \"sar\": {\n",
    "        \"time_decay\": [10, 20, 30],\n",
    "        \"similarity\": [\"jaccard\", \"cosine\"]\n",
    "    },\n",
    "    \"svd\": {\n",
    "        \"rank\": [40, 60, 80]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = cf_algorithms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_params = cf_params[algo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = generate_param_grid(algo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rank': 10, 'regParam': 0.01, 'alpha': 0.1},\n",
       " {'rank': 15, 'regParam': 0.01, 'alpha': 0.1}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ALSModel' object has no attribute 'recommendForUserSubset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3cfad89c27bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdfs_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendForUserSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOP_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdfs_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MovieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recommendations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MovieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ALSModel' object has no attribute 'recommendForUserSubset'"
     ]
    }
   ],
   "source": [
    "param_list = []\n",
    "metric_list = []\n",
    "\n",
    "for idx, param in enumerate(params):\n",
    "    als = ALS(\n",
    "        maxIter=15,\n",
    "        implicitPrefs=True,\n",
    "        coldStartStrategy='drop',\n",
    "        userCol=\"UserId\",\n",
    "        itemCol=\"MovieId\",\n",
    "        ratingCol=\"Rating\",\n",
    "        nonnegative=False,\n",
    "        **param\n",
    "    )\n",
    "\n",
    "    model = als.fit(dfs_train)\n",
    "\n",
    "    dfs_rec = model.recommendForUserSubset(dfs_valid, TOP_K)\n",
    "    dfs_pred = dfs_rec.select('MovieId', explode('recommendations').alias('r')) \\\n",
    "      .select('MovieId', 'r.*')\n",
    "\n",
    "    rank_eval = SparkRankingEvaluation(\n",
    "        rating_true=dfs_valid, \n",
    "        rating_pred=dfs_pred,\n",
    "        k=TOP_K, \n",
    "        relevancy_method=\"top_k\",\n",
    "        **header\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "          \"K\": rank_eval.k,\n",
    "          \"cluster\": cluster,\n",
    "          \"map\": rank_eval.map_at_k(),\n",
    "          \"ndcg\": rank_eval.ndcg_at_k(),\n",
    "          \"precision\": rank_eval.precision_at_k(),\n",
    "          \"recall\": rank_eval.recall_at_k()\n",
    "    }\n",
    "\n",
    "    param_list.append(param)\n",
    "    metric_list.append(results)\n",
    "\n",
    "    metric_current = results[SELECTION_METRIC]\n",
    "    if idx == 0:\n",
    "        metric_best = metric_current\n",
    "        rec_best = model\n",
    "        idx_best = idx\n",
    "    else:\n",
    "        if _is_better(metric_current, metric_best, SELECTION_METRIC):\n",
    "            metric_best = metric_current\n",
    "            results_best = results\n",
    "            param_best = param\n",
    "            rec_best = model\n",
    "            idx_best = idx\n",
    "            \n",
    "    dfs_rec = rec_best.recommendForUserSubset(dfs_test, TOP_K)\n",
    "    dfs_pred = dfs_rec.select('MovieId', explode('recommendations').alias('r')) \\\n",
    "      .select('MovieId', 'r.*')\n",
    "\n",
    "    rank_eval = SparkRankingEvaluation(\n",
    "        rating_true=dfs_valid, \n",
    "        rating_pred=dfs_pred,\n",
    "        k=TOP_K, \n",
    "        relevancy_method=\"top_k\",\n",
    "        **header\n",
    "    )\n",
    "\n",
    "    results_final = {\n",
    "        \"K\": rank_eval.k,\n",
    "        \"cluster\": cluster,\n",
    "        \"map\": rank_eval.map_at_k(),\n",
    "        \"ndcg\": rank_eval.ndcg_at_k(),\n",
    "        \"precision\": rank_eval.precision_at_k(),\n",
    "        \"recall\": rank_eval.recall_at_k()\n",
    "    }\n",
    "\n",
    "    df_result = pd.DataFrame(\n",
    "        {\n",
    "          \"K\": results_final[\"K\"],\n",
    "          \"cluster\": results_final[\"cluster\"],\n",
    "          \"MAP\": results_final[\"map\"],\n",
    "          \"nDCG@k\": results_final[\"ndcg\"],\n",
    "          \"Precision@k\": results_final[\"precision\"],\n",
    "          \"Recall@k\": results_final[\"recall\"]\n",
    "        }, \n",
    "        index=[0]\n",
    "    )\n",
    "\n",
    "    df_results = df_results.append(df_result, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recommender)",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
