{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# Movie recommender with multinomial RBM (Tensorflow, GPU)\n",
    "\n",
    "A Restricted Boltzmann Machine (RBM) is a generative neural network model used to perform unsupervised learning. The main task of an RBM is to learn the joint probability distribution $P(v,h)$, where $v$ are the visible units and $h$ the hidden ones. The hidden units represent latent variables while the visible units are clamped on the input data. Once the joint distribution is learnt, new examples are generated by sampling from it.  \n",
    "\n",
    "In this notebook, we provide an example of how to utilize the RBM to perform item recommendations. In particular, we use as a case study the [movielens dataset](https://movielens.org), comprising the ranking of movies (from 1 to 5) given by viewers. \n",
    "\n",
    "This notebook provides a quick start, showing the basic step to make the algorithm work and how to evaluate its output. A detailed discussion of the RBM model together with a deeper analysis of the recommendation task is provided in the [RBM Deep Dive section](/Recommenders/notebooks/02_modeling/rbm_deep_dive.ipynb). The RBM implementation presented here is based on the article by Ruslan Salakhutdinov, Andriy Mnih and Geoffrey Hinton [Restricted Boltzmann Machines for Collaborative Filtering](https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf) with the exception that here we use multinomial units instead of one-hot encoded. \n",
    "\n",
    "### Advantages of RBM: \n",
    "\n",
    "The model generates ratings for a user/movie pair using a collaborative filtering based approach. While matrix factorization methods learn how to reproduce an instance of the user/item affinity matrix, the RBM learns the underlying probability distribution. This has several advantages: \n",
    "\n",
    "- Generalizability : the model generalize well to new examples.\n",
    "- Stability in time: if the recommendation task is time-stationary, the model does not need to be trained often to accomodate new ratings/users. \n",
    "- Scales well with the size of the dataset and the sparsity of the user/affinity matrix. \n",
    "- The tensorflow implementation presented here allows fast training on GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global Settings and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.0 | packaged by conda-forge | (default, Feb  9 2017, 14:36:55) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Pandas version: 0.23.4\n"
     ]
    }
   ],
   "source": [
    "#load libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import papermill as pm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from reco_utils.recommender.rbm.Mrbm_tensorflow import RBM\n",
    "from reco_utils.dataset.rbm_splitters import splitter\n",
    "\n",
    "from reco_utils.dataset.url_utils import maybe_download\n",
    "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "#For interactive mode only\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Data \n",
    "\n",
    "Here we select the size of the movielens dataset. In this example we consider an intermediate size consisting of 1 milion ratings provided by approximally 6000 users on 4000 movies. The data are imported in a pandas dataframe including the user ID, the item ID, the ratings and a timestamp denoting when a particular user rated a particular item.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  timestamp\n",
       "0     196      242       3  881250949\n",
       "1     186      302       3  891717742\n",
       "2      22      377       1  878887116\n",
       "3     244       51       2  880606923\n",
       "4     166      346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MovieLens data have different data-format for each size of dataset \n",
    "data_header = None\n",
    "if MOVIELENS_DATA_SIZE == '100k':\n",
    "    separator = '\\t'\n",
    "    data_name = 'u.data'\n",
    "    data_folder = 'ml-100k'\n",
    "elif MOVIELENS_DATA_SIZE == '1m':\n",
    "    separator = '::'\n",
    "    data_name = 'ratings.dat'\n",
    "    data_folder = 'ml-1m'\n",
    "elif MOVIELENS_DATA_SIZE == '10m':\n",
    "    separator = '::'\n",
    "    data_name = 'ratings.dat'\n",
    "    data_folder = 'ml-10M100K'\n",
    "elif MOVIELENS_DATA_SIZE == '20m':\n",
    "    separator = ','\n",
    "    data_name = 'ratings.csv'\n",
    "    data_folder = 'ml-20m'\n",
    "    data_header = 0\n",
    "else:\n",
    "    raise ValueError('Invalid data size. Should be one of {100k, 1m, 10m, or 20m}') \n",
    "\n",
    "# Download dataset zip file and decompress if haven't done yet\n",
    "data_path = os.path.join(data_folder, data_name)\n",
    "if not os.path.exists(data_path):\n",
    "    filename = 'ml-' + MOVIELENS_DATA_SIZE + '.zip'\n",
    "    filepath = maybe_download('http://files.grouplens.org/datasets/movielens/'+filename, filename)\n",
    "\n",
    "    with ZipFile(filepath, 'r') as zf:\n",
    "        zf.extractall()\n",
    "    \n",
    "    # remove zip file we already used\n",
    "    os.remove(filepath)\n",
    "    \n",
    "data = pd.read_csv(\n",
    "    data_path,\n",
    "    sep=separator,\n",
    "    engine='python',\n",
    "    names=['userID','movieID','rating','timestamp'],\n",
    "    header=data_header\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the data using the stratified splitter  \n",
    "\n",
    "As a second step we split the data into train and test set. If you are familiar with training supervised learning model, here you will notice the first difference. In the former case, we cut off a certain proportion of training examples from dataset (e.g. images), here corresponding to users (or items), ending up with two matrices (train and test) having different row dimensions. Here we need to mantain the same matrix size for the train and test set, but the two will contain different amounts of ratings, see ... for more details.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating the user/item affinity matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix generated, sparsness: 93 % size: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "#to use standard names across the analysis \n",
    "header = {\n",
    "        \"col_user\": \"userID\",\n",
    "        \"col_item\": \"movieID\",\n",
    "        \"col_rating\": \"rating\",\n",
    "    }\n",
    "\n",
    "#instantiate the splitter \n",
    "split = splitter(DF = data, **header)\n",
    "\n",
    "Xtr, Xtst, train_df, test_df, maps = split.stratified_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The splitter returns several elements: \n",
    "\n",
    "- Xtr: a matrix containing the train set ratings \n",
    "- Xtst: a matrix containing the test elements \n",
    "\n",
    "Note that the train/test matrices have exactly the same same dimension, but different entries.\n",
    "\n",
    "`train_df` and `test_df` contain the same information as Xtr and Xtst but in dataframe format for later use. finally, `maps` is a dictionary we will use to map back the predicted ratings to their original user/item IDs. \n",
    "\n",
    "The `split()` method also returns informations on the sparsness of the dataset all dataset and the size of the user/affinity matrix. The former is a measure of the total number of zeroes (i.e. unrated movies) in the dataset. This is what makes a recommendation task hard: we try to predict 95% of the missing data with only 5% of information! Below we verufy that the generated train and test matrices have exactly the same dimension.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train matrix size (943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating\n",
       "0       1       55       5\n",
       "1       1      183       5\n",
       "2       1      150       5\n",
       "3       1      201       3\n",
       "4       1      184       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train matrix size', Xtr.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test matrix size (943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating\n",
       "0       1      203       4\n",
       "1       1       68       4\n",
       "2       1      157       4\n",
       "3       1      210       4\n",
       "4       1      146       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test matrix size', Xtst.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train the RBM model\n",
    "\n",
    "The model has been implemented as a Tensorflow (TF) class. TF does not support probabilistic models natively, so the implementation of the algorithm has a different structure to the one you may be used to see in popular supervised models; for details see ... Also, the class has been implemented so that the TF session is hidden inside the `fit()` method and no explicit call is needed. The algorithm operated in three different steps: \n",
    "\n",
    "- Model initialization: This is where we tell TF how to build the computational graph. The main parameters to specify are the number of hidden units, the number of training epochs and the minibatch size. Other parameters can be optionally tweaked for experimentation, as explained in ... \n",
    "\n",
    "- Model fit: This is where we train the model on the data. The method takes two arguments: the training and test set matrices. Note that the model is trained **only** on the training set, the set is used to display the generalization accuracy of the trained model, useful to have a first idea on the quality of training. \n",
    "\n",
    "- Model prediction: This is where we generate ratings for the unseen items. Once the model has been trained and we are satisfied with its overall accuracy, we sample new ratings from the learned distribution. In particular, we extract the top_k (e.g. 10) most relevant recommendation according to some predefined score. The prediction is then returned in dataframe format ready to be analysed and deployed.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "#First we initialize the model class\n",
    "model = RBM(hidden_units= 500, training_epoch = 5, minibatch_size= 100, keep_prob= 0.8, **header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first time the fit method is called it may take longer to return the result. This is due to the fact that TF needs to initialized the GPU session. You will notice that this is not the case when training the algorithm the second or more times.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the computational graph\n",
      "done training, Training time 0.6610372\n"
     ]
    }
   ],
   "source": [
    "#Model Fit\n",
    "train_time= model.fit(Xtr, Xtst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we can optionlly evauate the root mean squared error to have an idea of how the learning is proceeding. We would generally like to see this quantity decreasing as a function of the learning epochs. To visualise this choose `with_metrics = True` in the `RBM()` model function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done recommending items, time 0.1489252\n",
      "Formatting ouput\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "      <td>4.994137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>4.990410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>4.989939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>4.989878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>4.988818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>4.988594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>513</td>\n",
       "      <td>4.987560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>655</td>\n",
       "      <td>4.986586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "      <td>4.983791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>4.982819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  prediction\n",
       "0       1      197    4.994137\n",
       "1       1      430    4.990410\n",
       "2       1      202    4.989939\n",
       "3       1      198    4.989878\n",
       "4       1       89    4.988818\n",
       "5       1       61    4.988594\n",
       "6       1      513    4.987560\n",
       "7       1      655    4.986586\n",
       "8       1      651    4.983791\n",
       "9       1      249    4.982819"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model prediction\n",
    "\n",
    "#number of top score elements to be recommended  \n",
    "K = 10\n",
    "\n",
    "#Model prediction on the test set Xtst. Note that we pass 'maps' as a second argument in order to return the correct\n",
    "#user/item ids in a pandas dataframe format. \n",
    "top_k, test_time =  model.recommend_k_items(Xtst, maps)\n",
    "\n",
    "#show the first 10 elements of the dataframe for inspection \n",
    "top_k['userID'] = pd.to_numeric(top_k['userID'])\n",
    "top_k['movieID'] = pd.to_numeric(top_k['movieID'])\n",
    "\n",
    "top_k.head(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluation metrics \n",
    "\n",
    "Here we evaluate the performance of the algorithm using the metrics provided in the `PythonRankingEvaluation` class. Note that the following metrics take into account only the first K elements, therefore their value may be different from the one displayed from the `model.fit()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_metrics(\n",
    "    data_size,\n",
    "    data_true,\n",
    "    data_pred,\n",
    "    time_train,\n",
    "    time_test,\n",
    "    K\n",
    "):\n",
    "\n",
    "    eval_map = map_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                    col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                    relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_ndcg = ndcg_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                      col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                      relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_precision = precision_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                               col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                               relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    eval_recall = recall_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n",
    "                          col_rating=\"rating\", col_prediction=\"prediction\", \n",
    "                          relevancy_method=\"top_k\", k= K)\n",
    "\n",
    "    \n",
    "    df_result = pd.DataFrame(\n",
    "        {   \"Dataset\": data_size,\n",
    "            \"K\": K,\n",
    "            \"MAP\": eval_map,\n",
    "            \"nDCG@k\": eval_ndcg,\n",
    "            \"Precision@k\": eval_precision,\n",
    "            \"Recall@k\": eval_recall,\n",
    "            \"Train time\": time_train,\n",
    "            \"Test time\": time_test\n",
    "        }, \n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mv 100k</td>\n",
       "      <td>10</td>\n",
       "      <td>0.222598</td>\n",
       "      <td>0.565924</td>\n",
       "      <td>0.454189</td>\n",
       "      <td>0.281522</td>\n",
       "      <td>0.661037</td>\n",
       "      <td>0.148925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset   K       MAP    nDCG@k  Precision@k  Recall@k  Train time  \\\n",
       "0  mv 100k  10  0.222598  0.565924     0.454189  0.281522    0.661037   \n",
       "\n",
       "   Test time  \n",
       "0   0.148925  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_100k= ranking_metrics(\n",
    "    data_size = \"mv 100k\",\n",
    "    data_true =test_df,\n",
    "    data_pred =top_k,\n",
    "    time_train=train_time,\n",
    "    time_test =test_time,\n",
    "    K =10)\n",
    "\n",
    "eval_100k"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python (reco_full)",
   "language": "python",
   "name": "reco_full"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
