{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Benchmarking Collaborative Filtering Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmarking applies to collaborative filtering algorithms available in Microsoft/Recommenders repository like Spark ALS, Surprise SVD, Microsoft SAR, etc.\n",
    "\n",
    "## Experimentation setup:\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in recommending list of items.\n",
    "* Datasets\n",
    "  * Movielens 100K.\n",
    "  * Movielens 1M.\n",
    "  * Movielens 10M.\n",
    "  * Movielens 20M.\n",
    "* Data split\n",
    "  * The data is split into train and test sets.\n",
    "  * The split ratios are 75-25 for train and test datasets.\n",
    "  * The splitting is random. \n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * It is known that exhaustive search of the hyper parameter space is cubersome. Instead, empirical parameter values reported in the literature that generated optimal results are used.\n",
    "* Evaluation metrics\n",
    "  * Ranking metrics: \n",
    "    * Precision@k, Recall@k, Normalized discounted cumulative gain@k (NDCG@k), and Mean-average-precision (MAP). \n",
    "    * In the evaluation metrics above, k = 10. \n",
    "  * Rating metrics:\n",
    "    * Root Mean Squared Error (RMSE), Mean Average Error (MAE), R Squared, Explained Variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.0 | packaged by conda-forge | (default, Feb  9 2017, 14:36:55) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Spark version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import papermill as pm\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType\n",
    "\n",
    "import surprise\n",
    "\n",
    "from reco_utils.common.spark_utils import start_or_get_spark\n",
    "from reco_utils.dataset.movielens import load_spark_df, load_pandas_df\n",
    "from reco_utils.dataset.python_splitters import (\n",
    "    python_random_split, \n",
    "    python_chrono_split, \n",
    "    python_stratified_split\n",
    ")\n",
    "from reco_utils.recommender.sar.sar_singlenode import SARSingleNodeReference\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRankingEvaluation, SparkRatingEvaluation\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    rsquared,\n",
    "    exp_var\n",
    ")\n",
    "from reco_utils.evaluation.parameter_sweep import generate_param_grid\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Spark\n",
    "spark = start_or_get_spark(\"Benchmark\", memory=\"16g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "# MOVIELENS_DATA_SIZES = ['100k', '1m', '10m', '20m']\n",
    "MOVIELENS_DATA_SIZES = ['100k', '1m']\n",
    "\n",
    "# Set data schema\n",
    "headers = {\n",
    "    \"col_user\": \"UserId\",\n",
    "    \"col_item\": \"MovieId\",\n",
    "    \"col_timestamp\": \"Timestamp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CF algorithms available in the repo are comparatively studied. They are Spark ALS, SAR, and Surprise SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_algorithms = [\"als\", \"sar\", \"svd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(\n",
    "    spark,\n",
    "    data_train,\n",
    "    data_test,\n",
    "    data_size=\"100k\",\n",
    "    algo=\"als\",\n",
    "    col_user=\"UserId\",\n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\",\n",
    "    col_timestamp=\"Timestamp\",\n",
    "    **params\n",
    "):\n",
    "    if algo == \"als\":  \n",
    "        als = ALS(\n",
    "            implicitPrefs=False,\n",
    "            coldStartStrategy='drop',\n",
    "            userCol=col_user,\n",
    "            itemCol=col_item,\n",
    "            ratingCol=col_rating,\n",
    "            nonnegative=False,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        dfs_train = spark.createDataFrame(df_train)\n",
    "        dfs_test = spark.createDataFrame(df_test)\n",
    "\n",
    "        time_start = time.time()\n",
    "        model = als.fit(dfs_train)\n",
    "        time_train = time.time() - time_start\n",
    "\n",
    "        time_start = time.time()\n",
    "        \n",
    "        users = dfs_train.select('UserId').distinct()\n",
    "        items = dfs_train.select('MovieId').distinct()\n",
    "        user_item = users.crossJoin(items)\n",
    "        dfs_pred = model.transform(user_item)\n",
    "\n",
    "        # Remove seen items.\n",
    "        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "            dfs_train.alias(\"train\"),\n",
    "            (dfs_pred['UserId'] == dfs_train['UserId']) & (dfs_pred['MovieId'] == dfs_train['MovieId']),\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "        dfs_pred = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "            .select('pred.' + 'UserId', 'pred.' + 'MovieId', 'pred.' + \"prediction\")\n",
    "\n",
    "        time_test = time.time() - time_start\n",
    "        \n",
    "        df_pred = dfs_pred\n",
    "    elif algo == \"sar\":\n",
    "        model = SARSingleNodeReference(\n",
    "            remove_seen=True, \n",
    "            time_now=None, \n",
    "            timedecay_formula=True, \n",
    "            col_rating=col_rating,\n",
    "            **headers,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        data = data_train.append(data_test)\n",
    "\n",
    "        time_start = time.time()\n",
    "        unique_users = data[col_user].unique()\n",
    "        unique_items = data[col_item].unique()\n",
    "\n",
    "        enumerate_items_1, enumerate_items_2 = itertools.tee(enumerate(unique_items))\n",
    "        enumerate_users_1, enumerate_users_2 = itertools.tee(enumerate(unique_users))\n",
    "        item_map_dict = {x: i for i, x in enumerate_items_1}\n",
    "        user_map_dict = {x: i for i, x in enumerate_users_1}\n",
    "\n",
    "        index2user = dict(enumerate_users_2)\n",
    "        index2item = dict(enumerate_items_2)\n",
    "\n",
    "        model.set_index(unique_users, unique_items, user_map_dict, item_map_dict, index2user, index2item)\n",
    "\n",
    "        df_train_sar = df_train.copy()\n",
    "        model.fit(df_train_sar)\n",
    "        time_train = time.time() - time_start\n",
    "\n",
    "        time_start = time.time()\n",
    "        df_test_sar = df_test.copy()\n",
    "        top_k = model.recommend_k_items(df_test_sar)\n",
    "\n",
    "        top_k[col_user] = pd.to_numeric(top_k[col_user])\n",
    "        top_k[col_item] = pd.to_numeric(top_k[col_item])\n",
    "        time_test = time.time() - time_start\n",
    "\n",
    "        df_pred = top_k\n",
    "    elif algo == \"svd\":\n",
    "        df_train_svd = df_train[[col_user, col_item, col_rating]]\n",
    "        \n",
    "        surprise_data_size = \"1m\" if (data_size == \"10m\" or data_size == \"20m\") else data_size\n",
    "        train = surprise.Dataset.load_from_df(df_train_svd, reader=surprise.Reader('ml-' + surprise_data_size)).build_full_trainset()\n",
    "\n",
    "        svd = surprise.SVD(\n",
    "            verbose=False,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        time_start = time.time()\n",
    "        svd.fit(train)\n",
    "        time_train = time.time() - time_start\n",
    "\n",
    "        time_start = time.time()     \n",
    "        # To make sure the predictions include items in the overall dataset.\n",
    "        preds_lst = []\n",
    "        for user in df_train[col_user].unique():\n",
    "            for item in df_train[col_item].unique():\n",
    "                preds_lst.append([user, item, svd.predict(user, item).est])\n",
    "                \n",
    "        all_predictions = pd.DataFrame(data=preds_lst, columns=[col_user, col_item, \"prediction\"])\n",
    "        merged = pd.merge(df_train, all_predictions, on=[col_user, col_item], how=\"outer\")\n",
    "        all_predictions = merged[merged[col_rating].isnull()].drop(col_rating, axis=1)\n",
    "        \n",
    "        df_pred = all_predictions\n",
    "        \n",
    "        time_test = time.time() - time_start\n",
    "    else:\n",
    "        raise ValueError(\"No algorithm {} found\".format(algo))\n",
    "\n",
    "    return df_pred, time_train, time_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    spark,\n",
    "    algorithm,\n",
    "    data_pred,\n",
    "    data_true,\n",
    "    time_train,\n",
    "    time_test,\n",
    "    col_user=\"UserId\",\n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\",\n",
    "    col_prediction=\"prediction\",\n",
    "    k=TOP_K\n",
    "):\n",
    "    if algorithm == \"als\":\n",
    "        data_true = spark.createDataFrame(data_true)\n",
    "\n",
    "        ranking_eval = SparkRankingEvaluation(\n",
    "            data_true,\n",
    "            data_pred,\n",
    "            col_user=col_user,\n",
    "            col_item=col_item,\n",
    "            col_rating=col_rating,\n",
    "            col_prediction=col_prediction,\n",
    "            k=k \n",
    "        )\n",
    "        \n",
    "        rating_eval = SparkRatingEvaluation(\n",
    "            data_true,\n",
    "            data_pred,\n",
    "            col_user=col_user,\n",
    "            col_item=col_item,\n",
    "            col_rating=col_rating,\n",
    "            col_prediction=col_prediction\n",
    "        )\n",
    "        \n",
    "        eval_map = ranking_eval.map_at_k()\n",
    "        eval_precision = ranking_eval.precision_at_k()\n",
    "        eval_recall = ranking_eval.recall_at_k()\n",
    "        eval_ndcg = ranking_eval.ndcg_at_k()\n",
    "        \n",
    "        eval_rmse = rating_eval.rmse()\n",
    "        eval_mae = rating_eval.mae()\n",
    "        eval_r2 = rating_eval.rsquared()\n",
    "        eval_expvar = rating_eval.exp_var()\n",
    "    else:\n",
    "        # Ranking metrics.\n",
    "        eval_map = map_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        eval_ndcg = ndcg_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        eval_precision = precision_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        eval_recall = recall_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        # Rating metrics.\n",
    "        eval_rmse = rmse(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "\n",
    "        eval_mae = mae(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "\n",
    "        eval_r2 = rsquared(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "\n",
    "        eval_expvar = exp_var(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "    \n",
    "    df_result = pd.DataFrame(\n",
    "        {\n",
    "            \"Algo\": algorithm,\n",
    "            \"K\": TOP_K,\n",
    "            \"MAP\": eval_map,\n",
    "            \"nDCG@k\": eval_ndcg,\n",
    "            \"Precision@k\": eval_precision,\n",
    "            \"Recall@k\": eval_recall,\n",
    "            \"RMSE\": eval_rmse,\n",
    "            \"MAE\": eval_mae,\n",
    "            \"R2\": eval_r2,\n",
    "            \"Explained Variance\": eval_expvar,\n",
    "            \"Train time\": time_train,\n",
    "            \"Test time\": time_test\n",
    "        }, \n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a time-consuming hyper parameter searching, hyper parameters that are empirically selected to train models for each algorithms. These parameters are determined either by referencing to the literature or empirically.\n",
    "\n",
    "\n",
    "http://mymedialite.net/examples/datasets.html\n",
    "\n",
    "> num_factors=10 num_iter=75 reg=0.05 learn_rate=0.005\n",
    "> num_factors=160 bias_reg=0.003 reg_u=0.08 reg_i=0.1 learn_rate=0.07 num_iter=100 bold_driver=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_params = {\n",
    "    \"als\": {\n",
    "        \"rank\": 10,\n",
    "        \"regParam\": 0.05,\n",
    "        \"maxIter\": 15,\n",
    "        \"seed\": 123\n",
    "    },\n",
    "    \"sar\": {\n",
    "        \"time_decay_coefficient\": 30,\n",
    "        \"similarity_type\": \"jaccard\"\n",
    "    },\n",
    "    \"svd\": {\n",
    "        \"random_state\": 123,\n",
    "        \"n_factors\": 160,\n",
    "        \"n_epochs\": 100,\n",
    "        \"lr_all\": 0.07,\n",
    "        \"reg_bu\": 0.003,\n",
    "        \"reg_bi\": 0.003,\n",
    "        \"reg_pu\": 0.08,\n",
    "        \"reg_qi\": 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting user affinity matrix...\n",
      "Calculating time-decayed affinities...\n",
      "Creating index columns...\n",
      "Building user affinity sparse matrix...\n",
      "Calculating item cooccurrence...\n",
      "Calculating item similarity...\n",
      "Calculating jaccard...\n",
      "Calculating recommendation scores...\n",
      "done training\n",
      "Converting to dense matrix...\n",
      "Removing seen items...\n",
      "Getting top K...\n",
      "Select users from the test set\n",
      "Creating output dataframe...\n",
      "Formatting output\n",
      "Collecting user affinity matrix...\n",
      "Calculating time-decayed affinities...\n",
      "Creating index columns...\n",
      "Building user affinity sparse matrix...\n",
      "Calculating item cooccurrence...\n",
      "Calculating item similarity...\n",
      "Calculating jaccard...\n",
      "Calculating recommendation scores...\n",
      "done training\n",
      "Converting to dense matrix...\n",
      "Removing seen items...\n",
      "Getting top K...\n",
      "Select users from the test set\n",
      "Creating output dataframe...\n",
      "Formatting output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Train time</th>\n",
       "      <th>Test time</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.032687</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.972540</td>\n",
       "      <td>0.754861</td>\n",
       "      <td>0.263450</td>\n",
       "      <td>0.267639</td>\n",
       "      <td>1.560713</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>0.373197</td>\n",
       "      <td>0.326617</td>\n",
       "      <td>0.175957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.614257</td>\n",
       "      <td>0.111591</td>\n",
       "      <td>100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.033298</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>0.943537</td>\n",
       "      <td>0.742266</td>\n",
       "      <td>0.306726</td>\n",
       "      <td>0.306960</td>\n",
       "      <td>36.315219</td>\n",
       "      <td>26.767744</td>\n",
       "      <td>100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.030452</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.858593</td>\n",
       "      <td>0.677817</td>\n",
       "      <td>0.406883</td>\n",
       "      <td>0.413036</td>\n",
       "      <td>3.212321</td>\n",
       "      <td>0.068237</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064013</td>\n",
       "      <td>0.308012</td>\n",
       "      <td>0.277215</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.707066</td>\n",
       "      <td>0.819835</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.026010</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.895035</td>\n",
       "      <td>0.705428</td>\n",
       "      <td>0.355466</td>\n",
       "      <td>0.355749</td>\n",
       "      <td>371.703758</td>\n",
       "      <td>421.250064</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algo   K       MAP    nDCG@k  Precision@k  Recall@k      RMSE       MAE  \\\n",
       "0  als  10  0.003317  0.032687     0.038070  0.014183  0.972540  0.754861   \n",
       "1  sar  10  0.105815  0.373197     0.326617  0.175957       NaN       NaN   \n",
       "2  svd  10  0.003916  0.031961     0.033298  0.012646  0.943537  0.742266   \n",
       "3  als  10  0.001947  0.024127     0.030452  0.009260  0.858593  0.677817   \n",
       "4  sar  10  0.064013  0.308012     0.277215  0.109292       NaN       NaN   \n",
       "5  svd  10  0.003422  0.026010     0.024375  0.009772  0.895035  0.705428   \n",
       "\n",
       "         R2  Explained Variance  Train time   Test time  Data  \n",
       "0  0.263450            0.267639    1.560713    0.064856  100k  \n",
       "1       NaN                 NaN    0.614257    0.111591  100k  \n",
       "2  0.306726            0.306960   36.315219   26.767744  100k  \n",
       "3  0.406883            0.413036    3.212321    0.068237    1m  \n",
       "4       NaN                 NaN    8.707066    0.819835    1m  \n",
       "5  0.355466            0.355749  371.703758  421.250064    1m  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "\n",
    "for data_size in MOVIELENS_DATA_SIZES:\n",
    "    # Download data\n",
    "    data = load_pandas_df(size=data_size)\n",
    "\n",
    "    # Split data w.r.t the experimentation protocol.\n",
    "    df_train, df_test = python_random_split(data, ratio=0.75, seed=123)\n",
    "\n",
    "    for idx, algo in enumerate(cf_algorithms):\n",
    "        params = cf_params[algo]\n",
    "\n",
    "        df_pred, time_train, time_test = recommender(\n",
    "            spark=spark,\n",
    "            data_train=df_train,\n",
    "            data_test=df_test,\n",
    "            data_size=data_size,\n",
    "            algo=algo,\n",
    "            col_user=\"UserId\",\n",
    "            col_item=\"MovieId\",\n",
    "            col_rating=\"Rating\",\n",
    "            col_timestamp=\"Timestamp\",\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        df_result = compute_metrics(\n",
    "            spark=spark,\n",
    "            data_pred=df_pred,\n",
    "            data_true=df_test,\n",
    "            time_train=time_train,\n",
    "            time_test=time_test,\n",
    "            algorithm=algo,\n",
    "            col_user=\"UserId\",\n",
    "            col_item=\"MovieId\",\n",
    "            col_rating=\"Rating\",\n",
    "            col_prediction=\"prediction\",\n",
    "            k=TOP_K\n",
    "        )\n",
    "\n",
    "        # Rating metrics do not apply to certain algorithms.\n",
    "        if algo == \"sar\":\n",
    "            df_result[[\"RMSE\", \"MAE\", \"R2\", \"Explained Variance\"]] = np.nan\n",
    "\n",
    "        df_result[\"Data\"] = data_size\n",
    "            \n",
    "        df_results = df_results.append(df_result, ignore_index=True)\n",
    "        \n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Recommender)",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
