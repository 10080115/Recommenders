{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Benchmarking Collaborative Filtering Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmarking applies to collaborative filtering algorithms available in Microsoft/Recommenders repository like Spark ALS, Surprise SVD, Microsoft SAR, etc.\n",
    "\n",
    "## Experimentation setup:\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in recommending list of items.\n",
    "* Datasets\n",
    "  * Movielens 100K.\n",
    "  * Movielens 1M.\n",
    "  * Movielens 10M.\n",
    "  * Movielens 20M.\n",
    "* Data split\n",
    "  * The data is split into train and test sets.\n",
    "  * The split ratios are 75-25 for train and test datasets.\n",
    "  * The splitting is random. \n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * It is known that exhaustive search of the hyper parameter space is cubersome. Instead, empirical parameter values reported in the literature that generated optimal results are used.\n",
    "* Evaluation metrics\n",
    "  * Precision@k.\n",
    "  * Recall@k.\n",
    "  * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "  * Mean-average-precision (MAP). \n",
    "  * In the evaluation metrics above, k = 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.0 | packaged by conda-forge | (default, Feb  9 2017, 14:36:55) \n",
      "[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]\n",
      "Spark version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import papermill as pm\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType\n",
    "\n",
    "import surprise\n",
    "\n",
    "from reco_utils.dataset.movielens import load_spark_df, load_pandas_df\n",
    "from reco_utils.dataset.python_splitters import (\n",
    "    python_random_split, \n",
    "    python_chrono_split, \n",
    "    python_stratified_split\n",
    ")\n",
    "from reco_utils.recommender.sar.sar_singlenode import SARSingleNodeReference\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRankingEvaluation, SparkRatingEvaluation\n",
    "from reco_utils.evaluation.python_evaluation import (\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    rmse,\n",
    "    mae,\n",
    "    rsquared,\n",
    "    exp_var\n",
    ")\n",
    "from reco_utils.evaluation.parameter_sweep import generate_param_grid\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_PYTHON=/anaconda/envs/Recommender/bin/python\n",
      "env: PYSPARK_DRIVER_PYTHON=/anaconda/envs/Recommender/bin/python\n"
     ]
    }
   ],
   "source": [
    "%env PYSPARK_PYTHON=/anaconda/envs/Recommender/bin/python\n",
    "%env PYSPARK_DRIVER_PYTHON=/anaconda/envs/Recommender/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ALS pySpark\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .config(\"spark.executor.cores\", \"4\")\\\n",
    "    .config(\"spark.executor.memory\", \"8g\")\\\n",
    "    .config(\"spark.memory.fraction\", \"0.9\")\\\n",
    "    .config(\"spark.memory.stageFraction\", \"0.3\")\\\n",
    "    .config(\"spark.executor.instances\", 1)\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"36000s\")\\\n",
    "    .config(\"spark.network.timeout\", \"10000000s\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"50g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select Movielens data size: 100k, 1m, 10m, or 20m\n",
    "# MOVIELENS_DATA_SIZES = ['100k', '1m', '10m', '20m']\n",
    "MOVIELENS_DATA_SIZES = ['100k', '100k']\n",
    "\n",
    "# Set data schema\n",
    "headers = {\n",
    "    \"col_user\": \"UserId\",\n",
    "    \"col_item\": \"MovieId\",\n",
    "    \"col_timestamp\": \"Timestamp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CF algorithms available in the repo are comparatively studied. They are Spark ALS, SAR, and Surprise SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_algorithms = [\"als\", \"sar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(\n",
    "    spark,\n",
    "    data_train,\n",
    "    data_test,\n",
    "    data_size=\"100k\",\n",
    "    algo=\"als\",\n",
    "    col_user=\"UserId\",\n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\",\n",
    "    col_timestamp=\"Timestamp\",\n",
    "    **params\n",
    "):\n",
    "    if algo == \"als\":  \n",
    "        als = ALS(\n",
    "            implicitPrefs=True,\n",
    "            coldStartStrategy='drop',\n",
    "            userCol=col_user,\n",
    "            itemCol=col_item,\n",
    "            ratingCol=col_rating,\n",
    "            nonnegative=False,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        dfs_train = spark.createDataFrame(df_train)\n",
    "        dfs_test = spark.createDataFrame(df_test)\n",
    "\n",
    "        time_start = time.time()\n",
    "        model = als.fit(dfs_train)\n",
    "        time_train = time.time() - time_start\n",
    "\n",
    "        time_start = time.time()\n",
    "        \n",
    "        users = dfs_train.select('UserId').distinct()\n",
    "        items = dfs_train.select('MovieId').distinct()\n",
    "        user_item = users.crossJoin(items)\n",
    "        dfs_pred = model.transform(user_item)\n",
    "\n",
    "        # Remove seen items.\n",
    "        dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "            dfs_train.alias(\"train\"),\n",
    "            (dfs_pred['UserId'] == dfs_train['UserId']) & (dfs_pred['MovieId'] == dfs_train['MovieId']),\n",
    "            how='outer'\n",
    "        )\n",
    "\n",
    "        dfs_pred = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "            .select('pred.' + 'UserId', 'pred.' + 'MovieId', 'pred.' + \"prediction\")\n",
    "\n",
    "        time_test = time.time() - time_start\n",
    "        \n",
    "        df_pred = dfs_pred\n",
    "    elif algo == \"sar\":\n",
    "        model = SARSingleNodeReference(\n",
    "            remove_seen=True, \n",
    "            time_now=None, \n",
    "            timedecay_formula=True, \n",
    "            col_rating=col_rating,\n",
    "            **headers,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        data = data_train.append(data_test)\n",
    "\n",
    "        time_start = time.time()\n",
    "        unique_users = data[col_user].unique()\n",
    "        unique_items = data[col_item].unique()\n",
    "\n",
    "        enumerate_items_1, enumerate_items_2 = itertools.tee(enumerate(unique_items))\n",
    "        enumerate_users_1, enumerate_users_2 = itertools.tee(enumerate(unique_users))\n",
    "        item_map_dict = {x: i for i, x in enumerate_items_1}\n",
    "        user_map_dict = {x: i for i, x in enumerate_users_1}\n",
    "\n",
    "        index2user = dict(enumerate_users_2)\n",
    "        index2item = dict(enumerate_items_2)\n",
    "\n",
    "        model.set_index(unique_users, unique_items, user_map_dict, item_map_dict, index2user, index2item)\n",
    "\n",
    "        df_train_sar = df_train.copy()\n",
    "        model.fit(df_train_sar)\n",
    "        time_train = time.time() - time_start\n",
    "\n",
    "        time_start = time.time()\n",
    "        df_test_sar = df_test.copy()\n",
    "        top_k = model.recommend_k_items(df_test_sar)\n",
    "\n",
    "        top_k[col_user] = pd.to_numeric(top_k[col_user])\n",
    "        top_k[col_item] = pd.to_numeric(top_k[col_item])\n",
    "        time_test = time.time() - time_start\n",
    "\n",
    "        df_pred = top_k\n",
    "    elif algo == \"svd\":\n",
    "        df_train_svd = df_train[[col_user, col_item, col_rating]]\n",
    "        \n",
    "        surprise_data_size = \"1m\" if (data_size == \"10m\" or data_size == \"20m\") else data_size\n",
    "        train = surprise.Dataset.load_from_df(df_train_svd, reader=surprise.Reader('ml-' + surprise_data_size)).build_full_trainset()\n",
    "\n",
    "        svd = surprise.SVD(\n",
    "            verbose=False,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        time_start = time.time()\n",
    "        svd.fit(train)\n",
    "        time_train = time.time() - time_start\n",
    "\n",
    "        time_start = time.time()     \n",
    "        # To make sure the predictions include items in the overall dataset.\n",
    "        preds_lst = []\n",
    "        for user in df_train[col_user].unique():\n",
    "            for item in df_train[col_item].unique():\n",
    "                preds_lst.append([user, item, svd.predict(user, item).est])\n",
    "                \n",
    "        all_predictions = pd.DataFrame(data=preds_lst, columns=[col_user, col_item, \"prediction\"])\n",
    "        merged = pd.merge(df_train, all_predictions, on=[col_user, col_item], how=\"outer\")\n",
    "        all_predictions = merged[merged[col_rating].isnull()].drop(col_rating, axis=1)\n",
    "        \n",
    "        df_pred = all_predictions\n",
    "        \n",
    "        time_test = time.time() - time_start\n",
    "    else:\n",
    "        raise ValueError(\"No algorithm {} found\".format(algo))\n",
    "\n",
    "    return df_pred, time_train, time_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    spark,\n",
    "    algorithm,\n",
    "    data_pred,\n",
    "    data_true,\n",
    "    time_train,\n",
    "    time_test,\n",
    "    col_user=\"UserId\",\n",
    "    col_item=\"MovieId\",\n",
    "    col_rating=\"Rating\",\n",
    "    col_prediction=\"prediction\",\n",
    "    k=TOP_K\n",
    "):\n",
    "    if algorithm == \"als\":\n",
    "        data_true = spark.createDataFrame(data_true)\n",
    "\n",
    "        ranking_eval = SparkRankingEvaluation(\n",
    "            data_true,\n",
    "            data_pred,\n",
    "            col_user=col_user,\n",
    "            col_item=col_item,\n",
    "            col_rating=col_rating,\n",
    "            col_prediction=col_prediction,\n",
    "            k=k \n",
    "        )\n",
    "        \n",
    "        rating_eval = SparkRatingEvaluation(\n",
    "            data_true,\n",
    "            data_pred,\n",
    "            col_user=col_user,\n",
    "            col_item=col_item,\n",
    "            col_rating=col_rating,\n",
    "            col_prediction=col_prediction\n",
    "        )\n",
    "        \n",
    "        eval_map = ranking_eval.map_at_k()\n",
    "        eval_precision = ranking_eval.precision_at_k()\n",
    "        eval_recall = ranking_eval.recall_at_k()\n",
    "        eval_map = ranking_eval.map_at_k()\n",
    "        \n",
    "        eval_rmse = rating_eval.rmse()\n",
    "        eval_mae = rating_eval.mae()\n",
    "        eval_r2 = rating_eval.rsquared()\n",
    "        eval_expvar = rating_eval.exp_var()\n",
    "    else:\n",
    "        # Ranking metrics.\n",
    "        eval_map = map_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        eval_ndcg = ndcg_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        eval_precision = precision_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        eval_recall = recall_at_k(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction, \n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        # Rating metrics.\n",
    "        eval_rmse = rmse(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "\n",
    "        eval_mae = mae(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "\n",
    "        eval_r2 = rsquared(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "\n",
    "        eval_expvar = exp_var(\n",
    "            data_true, data_pred, \n",
    "            col_user=col_user, col_item=col_item, col_rating=col_rating, col_prediction=col_prediction\n",
    "        )\n",
    "    \n",
    "    df_result = pd.DataFrame(\n",
    "        {\n",
    "            \"Algo\": algorithm,\n",
    "            \"K\": TOP_K,\n",
    "            \"MAP\": eval_map,\n",
    "            \"nDCG@k\": eval_ndcg,\n",
    "            \"Precision@k\": eval_precision,\n",
    "            \"Recall@k\": eval_recall,\n",
    "            \"RMSE\": eval_rmse,\n",
    "            \"MAE\": eval_mae,\n",
    "            \"R2\": eval_r2,\n",
    "            \"Explained Variance\": eval_expvar,\n",
    "            \"Train time\": time_train,\n",
    "            \"Test time\": time_test\n",
    "        }, \n",
    "        index=[0]\n",
    "    )\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a time-consuming hyper parameter searching, hyper parameters that are empirically selected to train models for each algorithms. These parameters are determined either by referencing to the literature or empirically.\n",
    "\n",
    "\n",
    "http://mymedialite.net/examples/datasets.html\n",
    "\n",
    "> num_factors=10 num_iter=75 reg=0.05 learn_rate=0.005\n",
    "> num_factors=160 bias_reg=0.003 reg_u=0.08 reg_i=0.1 learn_rate=0.07 num_iter=100 bold_driver=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_params = {\n",
    "    \"als\": {\n",
    "        \"rank\": 10,\n",
    "        \"regParam\": 0.05,\n",
    "        \"maxIter\": 15,\n",
    "        \"seed\": 123\n",
    "    },\n",
    "    \"sar\": {\n",
    "        \"time_decay_coefficient\": 30,\n",
    "        \"similarity_type\": \"jaccard\"\n",
    "    },\n",
    "    \"svd\": {\n",
    "        \"random_state\": 123,\n",
    "        \"n_factors\": 160,\n",
    "        \"n_epochs\": 100,\n",
    "        \"lr_all\": 0.07,\n",
    "        \"reg_bu\": 0.003,\n",
    "        \"reg_bi\": 0.003,\n",
    "        \"reg_pu\": 0.08,\n",
    "        \"reg_qi\": 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()\n",
    "\n",
    "for data_size in MOVIELENS_DATA_SIZES:\n",
    "    # Download data\n",
    "    data = load_pandas_df(size=data_size)\n",
    "\n",
    "    # Split data w.r.t the experimentation protocol.\n",
    "    df_train, df_test = python_random_split(data, ratio=0.75, seed=123)\n",
    "\n",
    "    for idx, algo in enumerate(cf_algorithms):\n",
    "        params = cf_params[algo]\n",
    "\n",
    "        df_pred, time_train, time_test = recommender(\n",
    "            spark=spark,\n",
    "            data_train=df_train,\n",
    "            data_test=df_test,\n",
    "            data_size=data_size,\n",
    "            algo=algo,\n",
    "            col_user=\"UserId\",\n",
    "            col_item=\"MovieId\",\n",
    "            col_rating=\"Rating\",\n",
    "            col_timestamp=\"Timestamp\",\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        df_result = compute_metrics(\n",
    "            spark=spark,\n",
    "            data_pred=df_pred,\n",
    "            data_true=df_test,\n",
    "            time_train=time_train,\n",
    "            time_test=time_test,\n",
    "            algorithm=algo,\n",
    "            col_user=\"UserId\",\n",
    "            col_item=\"MovieId\",\n",
    "            col_rating=\"Rating\",\n",
    "            col_prediction=\"prediction\",\n",
    "            k=TOP_K\n",
    "        )\n",
    "\n",
    "        # Rating metrics do not apply to certain algorithms.\n",
    "        if algo == \"sar\":\n",
    "            df_result[[\"RMSE\", \"MAE\", \"R2\", \"Explained Variance\"]] = np.nan\n",
    "\n",
    "        df_result[\"Data\"] = data_size\n",
    "            \n",
    "        df_results = df_results.append(df_result, ignore_index=True)\n",
    "        \n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Recommender)",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
